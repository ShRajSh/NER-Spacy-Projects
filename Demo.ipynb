{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_formatter(sentences, tag_list):\n",
    "    final_data = []\n",
    "\n",
    "    for  (tags, sentence) in zip(tags_list, sentences):\n",
    "        data = []\n",
    "        entities = {\"entities\": []}\n",
    "        start = 0\n",
    "        end = 0\n",
    "        data.append(\" \".join(sentence))\n",
    "        for tag, word in zip(tags, sentence):\n",
    "            end += len(word)\n",
    "            if tag != \"O\":\n",
    "                entities[\"entities\"].append((start, end, tag))\n",
    "            start += len(word) + 1\n",
    "            end += 1\n",
    "        data.append(entities)\n",
    "        final_data.append(data)\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-geo' 'B-gpe' 'B-per' 'I-geo' 'B-org' 'I-org' 'B-tim' 'B-art'\n",
      " 'I-art' 'I-per' 'I-gpe' 'I-tim' 'B-nat' 'B-eve' 'I-eve' 'I-nat']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Tag\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\n",
    "sentences = df.groupby('Sentence #')['Word'].apply(list).values\n",
    "tags_list = df.groupby('Sentence #')[\"Tag\"].apply(list).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.'] ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0], tags_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .',\n",
       " {'entities': [(48, 54, 'B-geo'), (77, 81, 'B-geo'), (111, 118, 'B-gpe')]}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Req Data Format: \n",
    "# [\n",
    "#     'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .', \n",
    "#     {'entities': [(48, 54, 'B-geo'), (77, 81, 'B-geo'), (111, 118, 'B-gpe')]}\n",
    "# ]\n",
    "\n",
    "\n",
    "formatted_data = data_formatter(sentences, tags_list)\n",
    "formatted_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(formatted_data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train, open(\"assets/train.pickle\", \"wb\"))\n",
    "pickle.dump(test, open(\"assets/val.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Running workflow 'all'\u001b[0m\n",
      "\u001b[1m\n",
      "================================= preprocess =================================\u001b[0m\n",
      "Running command: /usr/bin/python3 scripts/preprocess.py assets/train.pickle corpus/train.spacy\n",
      "Running command: /usr/bin/python3 scripts/preprocess.py assets/val.pickle corpus/val.spacy\n",
      "\u001b[1m\n",
      "=================================== train ===================================\u001b[0m\n",
      "Running command: /usr/bin/python3 -m spacy train configs/config.cfg --output training/ --paths.train corpus/train.spacy --paths.dev corpus/val.spacy\n",
      "\u001b[38;5;4mℹ Saving to output directory: training\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2021-11-14 20:29:50,078] [INFO] Set up nlp object from config\n",
      "[2021-11-14 20:29:50,088] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2021-11-14 20:29:50,102] [INFO] Created vocabulary\n",
      "[2021-11-14 20:29:50,105] [INFO] Finished initializing nlp object\n",
      "[2021-11-14 20:30:19,671] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     55.62    0.00    0.00    0.00    0.00\n",
      "  0     200         16.50  19044.74    0.00    0.00    0.00    0.00\n",
      "  0     400         83.92   7853.32    0.02    3.26    0.01    0.00\n",
      "  0     600         79.88   5445.76   22.48   26.20   19.69    0.22\n",
      "  0     800        110.07   5971.66   23.25   25.98   21.05    0.23\n",
      "  0    1000        145.23   7184.32   27.32   29.96   25.11    0.27\n",
      "  0    1200        201.15   8259.59   39.50   41.89   37.38    0.40\n",
      "  0    1400        284.98   9335.75   45.07   47.68   42.73    0.45\n",
      "  0    1600        776.60  10770.31   49.46   52.57   46.71    0.49\n",
      "  0    1800        673.91  12460.74   55.90   58.40   53.61    0.56\n",
      "  0    2000        766.64  14213.77   61.85   63.68   60.11    0.62\n",
      "  1    2200       1000.84  15877.77   65.71   67.25   64.25    0.66\n",
      "  1    2400       1254.90  17673.09   69.03   70.57   67.55    0.69\n",
      "  1    2600       1310.87  16761.55   71.21   72.34   70.12    0.71\n",
      "  1    2800       1379.06  16142.82   72.53   73.85   71.26    0.73\n",
      "  2    3000       1655.34  15679.01   74.21   75.65   72.82    0.74\n",
      "  2    3200       1388.03  14767.32   74.94   76.01   73.90    0.75\n",
      "  2    3400       1413.43  14418.92   75.71   76.67   74.78    0.76\n",
      "  2    3600       1386.47  13865.89   76.57   77.45   75.71    0.77\n",
      "  3    3800       1557.15  13785.93   77.10   77.97   76.25    0.77\n",
      "  3    4000       1381.93  13108.03   77.57   78.77   76.39    0.78\n",
      "  3    4200       1705.59  13037.02   77.94   79.37   76.57    0.78\n",
      "  3    4400       1789.52  13099.80   78.34   79.31   77.40    0.78\n",
      "  4    4600       1437.01  12488.08   78.82   79.70   77.96    0.79\n",
      "  4    4800       1780.16  12471.12   79.06   80.30   77.87    0.79\n",
      "  4    5000       2964.72  12181.02   79.48   80.35   78.64    0.79\n",
      "  4    5200       2261.94  12359.13   79.74   80.81   78.71    0.80\n",
      "  5    5400       1869.36  11941.28   80.00   81.09   78.94    0.80\n",
      "  5    5600       1367.31  11727.02   80.07   80.95   79.22    0.80\n",
      "  5    5800       1834.66  11826.96   80.28   81.39   79.20    0.80\n",
      "  6    6000       1360.74  11266.51   80.45   81.24   79.67    0.80\n",
      "  6    6200       1586.34  11561.73   80.59   81.51   79.70    0.81\n",
      "  6    6400       1406.42  11109.31   80.81   81.68   79.97    0.81\n",
      "  6    6600       1437.32  11313.96   81.05   81.97   80.16    0.81\n",
      "  7    6800       1368.38  10944.88   81.09   82.12   80.09    0.81\n",
      "  7    7000       1376.76  11076.91   81.23   82.33   80.16    0.81\n",
      "  7    7200       1320.56  10449.73   81.23   82.37   80.12    0.81\n",
      "  7    7400       1402.44  10965.25   81.42   82.37   80.48    0.81\n",
      "  8    7600       1353.80  10629.69   81.46   82.23   80.71    0.81\n",
      "  8    7800       1368.88  10722.46   81.53   82.37   80.69    0.82\n",
      "  8    8000       1364.12  10485.60   81.70   82.73   80.70    0.82\n",
      "  8    8200       1326.26  10314.23   81.79   82.61   80.98    0.82\n",
      "  9    8400       1360.81  10399.47   81.85   82.58   81.14    0.82\n",
      "  9    8600       1364.37  10436.39   81.94   82.82   81.08    0.82\n",
      "  9    8800       1331.52  10091.91   82.02   82.62   81.43    0.82\n",
      "  9    9000       1349.93  10207.92   82.19   83.06   81.34    0.82\n",
      " 10    9200       1366.34  10302.79   82.24   83.05   81.44    0.82\n",
      " 10    9400       1345.57  10102.58   82.29   83.04   81.56    0.82\n",
      " 10    9600       1370.20  10187.02   82.34   83.11   81.58    0.82\n",
      " 11    9800       1334.06   9893.09   82.43   83.32   81.56    0.82\n",
      " 11   10000       1303.35   9675.06   82.45   83.28   81.63    0.82\n",
      " 11   10200       1374.82  10042.63   82.57   83.43   81.74    0.83\n",
      " 11   10400       1350.39   9885.84   82.61   83.60   81.64    0.83\n",
      " 12   10600       1315.35   9638.89   82.61   83.62   81.63    0.83\n",
      " 12   10800       1327.25   9695.86   82.65   83.19   82.12    0.83\n",
      " 12   11000       1537.78   9874.35   82.65   83.49   81.82    0.83\n",
      " 12   11200       1355.77   9912.44   82.70   83.49   81.94    0.83\n",
      " 13   11400       1323.12   9561.80   82.74   83.36   82.12    0.83\n",
      " 13   11600       1332.26   9498.39   82.74   83.48   82.02    0.83\n",
      " 13   11800       1365.21   9819.64   82.83   83.50   82.17    0.83\n",
      " 13   12000       1329.01   9555.56   82.89   83.61   82.18    0.83\n",
      " 14   12200       1306.73   9289.76   82.92   83.58   82.27    0.83\n",
      " 14   12400       1343.26   9499.01   82.90   83.60   82.22    0.83\n",
      " 14   12600       1351.32   9484.10   83.00   83.70   82.30    0.83\n",
      " 14   12800       1346.84   9455.35   83.06   83.75   82.37    0.83\n",
      " 15   13000       1373.81   9521.74   83.08   83.72   82.45    0.83\n",
      " 15   13200       1311.75   9205.26   83.04   83.83   82.26    0.83\n",
      " 15   13400       1348.93   9470.67   83.05   83.86   82.26    0.83\n",
      " 16   13600       1342.37   9380.54   83.14   84.00   82.31    0.83\n",
      " 16   13800       1354.70   9412.12   83.14   83.94   82.37    0.83\n",
      " 16   14000       1351.58   9306.32   83.17   83.77   82.58    0.83\n",
      " 16   14200       1295.88   8942.14   83.23   84.07   82.41    0.83\n",
      " 17   14400       1370.35   9431.09   83.18   83.76   82.61    0.83\n",
      " 17   14600       1330.52   9157.49   83.26   84.15   82.38    0.83\n",
      " 17   14800       1294.81   8941.03   83.28   84.10   82.48    0.83\n",
      " 17   15000       1351.02   9262.87   83.28   83.91   82.67    0.83\n",
      " 18   15200       1353.75   9257.73   83.28   84.08   82.50    0.83\n",
      " 18   15400       1346.79   9156.98   83.29   84.05   82.55    0.83\n",
      " 18   15600       1363.63   9250.33   83.21   83.89   82.54    0.83\n",
      " 18   15800       1333.28   9065.08   83.35   84.04   82.67    0.83\n",
      " 19   16000       1337.88   9074.96   83.39   84.11   82.69    0.83\n",
      " 19   16200       1356.74   9176.67   83.42   84.15   82.71    0.83\n",
      " 19   16400       1318.58   8854.92   83.37   84.06   82.69    0.83\n",
      " 19   16600       1357.42   9167.33   83.39   84.09   82.71    0.83\n",
      " 20   16800       1333.55   8963.03   83.40   84.07   82.75    0.83\n",
      " 20   17000       1350.49   9130.88   83.40   84.18   82.63    0.83\n",
      " 20   17200       1373.26   9142.49   83.47   84.03   82.91    0.83\n",
      " 21   17400       1352.90   9038.02   83.41   84.02   82.80    0.83\n",
      " 21   17600       1335.75   9004.47   83.45   84.05   82.86    0.83\n",
      " 21   17800       1383.25   9164.81   83.44   84.11   82.78    0.83\n",
      " 21   18000       1370.25   9159.97   83.46   84.24   82.70    0.83\n",
      " 22   18200       1292.55   8747.15   83.45   84.23   82.68    0.83\n",
      " 22   18400       1332.72   8827.74   83.46   84.16   82.76    0.83\n",
      " 22   18600       1371.34   9087.70   83.48   84.11   82.86    0.83\n",
      " 22   18800       1383.18   9212.65   83.50   84.17   82.83    0.83\n",
      " 23   19000       1309.17   8709.09   83.49   84.14   82.85    0.83\n",
      " 23   19200       1338.93   8876.29   83.49   84.20   82.78    0.83\n",
      " 23   19400       1369.55   9098.36   83.51   84.20   82.83    0.84\n",
      " 23   19600       1357.20   8929.52   83.49   84.16   82.83    0.83\n",
      " 24   19800       1344.69   8984.38   83.51   84.17   82.86    0.84\n",
      " 24   20000       1365.58   8963.55   83.50   84.16   82.85    0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "training/model-last\n",
      "\u001b[1m\n",
      "================================== evaluate ==================================\u001b[0m\n",
      "Running command: /usr/bin/python3 -m spacy evaluate training/model-best corpus/val.spacy --output training/metrics.json\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK     100.00\n",
      "NER P   84.17 \n",
      "NER R   82.86 \n",
      "NER F   83.51 \n",
      "SPEED   32941 \n",
      "\n",
      "\u001b[1m\n",
      "=============================== NER (per type) ===============================\u001b[0m\n",
      "\n",
      "             P       R       F\n",
      "B-org    77.04   69.83   73.26\n",
      "B-geo    83.25   91.19   87.04\n",
      "B-tim    92.43   88.31   90.32\n",
      "I-org    78.93   75.58   77.22\n",
      "I-tim    84.86   72.01   77.91\n",
      "B-gpe    95.26   93.05   94.14\n",
      "B-per    82.00   79.27   80.61\n",
      "I-per    82.81   89.14   85.86\n",
      "I-geo    79.64   76.62   78.10\n",
      "B-art     0.00    0.00    0.00\n",
      "B-nat     0.00    0.00    0.00\n",
      "I-gpe   100.00   38.71   55.81\n",
      "B-eve    85.71   22.64   35.82\n",
      "I-eve     0.00    0.00    0.00\n",
      "I-art     0.00    0.00    0.00\n",
      "I-nat     0.00    0.00    0.00\n",
      "\n",
      "\u001b[38;5;2m✔ Saved results to training/metrics.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!spacy project run all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
